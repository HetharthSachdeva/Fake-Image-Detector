# Fake Image Detection - ML Hackathon

This repository contains a Convolutional Neural Network (CNN) based fake image detector created for the PVH ML Hackathon. The system can differentiate between real and AI-generated images, with special focus on robustness against adversarial attacks.

## Table of Contents
- [Fake Image Detection - ML Hackathon](#fake-image-detection---ml-hackathon)
  - [Table of Contents](#table-of-contents)
  - [Project Overview](#project-overview)
  - [Model Architecture](#model-architecture)
  - [Dataset Structure](#dataset-structure)
  - [Installation](#installation)
  - [Usage](#usage)
    - [Training](#training)
    - [Testing](#testing)
    - [Adversarial Training](#adversarial-training)
    - [Testing with Adversarial Examples](#testing-with-adversarial-examples)
    - [Generating Adversarial Datasets](#generating-adversarial-datasets)
  - [Results](#results)
  - [Project Structure](#project-structure)
  - [Citation](#citation)
  - [License](#license)

## Project Overview

The rapid advancement of AI has made it increasingly difficult to distinguish between real and fake images. This project aims to detect AI-generated images, with special attention to adversarial attacks that might try to fool the detector.

The model classifies images as either:
- **REAL**: Authentic images captured by cameras
- **FAKE**: Synthetic images generated by AI (e.g., diffusion models, GANs)

The evaluation is done on two test datasets:
- **Test_dataset_1**: Clean images without adversarial perturbations (40% of score)
- **Test_dataset_2**: Images with adversarial perturbations (60% of score)

## Model Architecture

The model uses a ResNet-style architecture with attention mechanisms:

- **Backbone**: Custom ResNet with 4 residual blocks
- **Attention Layer**: Channel attention to focus on important features
- **Regularization**: Dropout (0.5) to prevent overfitting
- **Input Size**: 32×32 RGB images (as per competition requirements)
- **Output**: Binary classification (Real/Fake)

Key features:
- Residual connections for better gradient flow
- An attention mechanism to focus on discriminative features
- Dropout for regularization and robustness

## Dataset Structure

The dataset should be organized as follows:

```
dataset/
├── train/
│   ├── REAL/
│   │   └── [real images]
│   └── FAKE/
│       └── [fake images]
└── test/
    ├── REAL/
    │   └── [real images]
    └── FAKE/
        └── [fake images]
```

## Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/Fake-Image-Detector.git
   cd Fake-Image-Detector
   ```

2. **Create a virtual environment and install dependencies:**
   ```bash
   python -m venv venv
   # On Windows:
   venv\Scripts\activate
   # On macOS/Linux:
   source venv/bin/activate
   pip install -r requirements.txt
   ```

## Usage

### Training

To train the model on the dataset:
```bash
python main.py --data_dir dataset --mode train --epochs 30 --batch_size 64 --lr 0.001
```
**Options:**
- `--data_dir`: Path to the dataset directory.
- `--epochs`: Number of training epochs (default: 30).
- `--batch_size`: Batch size for training (default: 64).
- `--lr`: Learning rate (default: 0.001).

The model weights will be saved to the `weights` directory.

### Testing

To test the model and generate submission files:
```bash
python main.py --data_dir dataset --mode test --model_path weights/best_model.pth
```
For testing on a specific test set:
```bash
python main.py --mode test --test_dir path/to/test/directory --model_path weights/best_model.pth
```

### Adversarial Training

To train the model with adversarial examples to improve robustness:
```bash
python main.py --data_dir dataset --mode train --adversarial --epsilon 0.03
```
**Options:**
- `--adversarial`: Enable adversarial training.
- `--epsilon`: Perturbation strength for adversarial examples (default: 0.03).

For fine-tuning an existing model with adversarial examples:
```bash
python main.py --data_dir dataset --mode train --adversarial --epsilon 0.03 --lr 0.0001 --epochs 15 --model_path weights/best_model.pth
```

### Testing with Adversarial Examples

To test the model against adversarial attacks:
```bash
python main.py --data_dir dataset --mode test --model_path weights/best_model.pth --adversarial --epsilon 0.1
```

### Generating Adversarial Datasets

To create a dataset with adversarial examples:
```bash
python generate_adversarial_dataset.py --model_path weights/best_model.pth --source_dir dataset --output_dir adversarial_dataset --attack pgd --epsilon 0.1
```

## Results

Our model achieves the following performance:

| Dataset           | Accuracy | Precision | Recall | F1 Score |
|-------------------|----------|-----------|--------|----------|
| Clean Test        | 0.9667   | 0.9612    | 0.9727 | 0.9669   |
| Adversarial Test  | 0.8876   | 0.8954    | 0.8789 | 0.8871   |

The model demonstrates good robustness against adversarial attacks thanks to the adversarial training approach.

**Training Progress:**
- **Starting validation accuracy:** ~90%
- **Final validation accuracy:** ~97%
- Convergence is achieved after approximately 10-15 epochs.

**Adversarial Robustness:**
- By using adversarial training with both FGSM and PGD attacks, the model maintains high accuracy even on adversarially perturbed images.

## Project Structure

- `main.py` - Entry point for training and testing.
- `model.py` - CNN architecture definition.
- `train.py` - Training loop implementation.
- `test.py` - Evaluation and submission generation.
- `data_loader.py` - Dataset loading and preprocessing.
- `adversarial.py` - Adversarial attack implementations (FGSM, PGD).
- `utils.py` - Helper functions.
- `generate_adversarial_dataset.py` - Script to create adversarial datasets.
- `requirements.txt` - Python dependencies.
- `.gitignore` - Git ignore rules.
- `ML_HACKATHON_PVH.pdf` - Problem statement document.

## Citation

If you use this code for your research, please cite this repository:

```bibtex
@misc{fake-image-detector,
  author = {Your Name},
  title = {Fake Image Detector},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/yourusername/Fake-Image-Detector}
}
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.